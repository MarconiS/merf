{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/sergiomarconi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/sergiomarconi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/sergiomarconi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/sergiomarconi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/sergiomarconi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/sergiomarconi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/sergiomarconi/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/sergiomarconi/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/sergiomarconi/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/sergiomarconi/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/sergiomarconi/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/sergiomarconi/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from merf import MERF\n",
    "from merf import ccbid\n",
    "from merf import outliers\n",
    "from merf import transform\n",
    "from merf import resample\n",
    "import warnings\n",
    "#ignore warnings about depracated packages\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class argv:\n",
    "    input = \"/Users/sergiomarconi/Documents/GitHub/ccb-id/ccbid/support_files/vst_training.csv\"\n",
    "    crowns = \"/Users/sergiomarconi/Documents/GitHub/ccb-id/ccbid/support_files/vst_species_id.csv\"\n",
    "    reducer = \"/Users/sergiomarconi/Documents/GitHub/ccb-id/ccbid/support_files/reducer.pck\"\n",
    "    n_features = 15\n",
    "    bands = \"/Users/sergiomarconi/Documents/GitHub/ccb-id/ccbid/support_files/neon-bands.csv\"\n",
    "    remove_outliers = 'PCA'\n",
    "    threshold = 3\n",
    "    split = 'sample'\n",
    "    tune = True\n",
    "    feature_selection = True\n",
    "    output = \"./model/ensemble\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get single site\n",
    "training_id = pd.read_csv(argv.crowns)\n",
    "training_id = training_id.drop_duplicates() \n",
    "st = 'MERF'\n",
    "\n",
    "features = pd.read_csv(argv.input)\n",
    "augmented_matrix= training_id.merge(features, left_on=\"crown_id\", right_on=\"crown_id\") \n",
    "training_id = (augmented_matrix.iloc[:,0])\n",
    "features = augmented_matrix.drop(columns=[\"species_id\", \"genus_id\", \"species\", \"genus\"])\n",
    "features.siteID=pd.Categorical(features.siteID)\n",
    "sites_labels = features.siteID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [utils.py:141] NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "crown_id = (augmented_matrix[['crown_id']]['crown_id'])\n",
    "species_id = (augmented_matrix[['species_id']]['species_id'])\n",
    "species_name = augmented_matrix[\"genus\"] + \" \" + augmented_matrix[\"species\"]\n",
    "np.random.seed(1984)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_unique, crowns_unique, crown_labels = ccbid.match_species_ids(training_id, crown_id, species_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique labels and crown id's\n",
    "#crown_id, label_id, labels\n",
    "unique_labels = np.unique(species_id)\n",
    "unique_crowns = np.unique(training_id)\n",
    "n_crowns = len(unique_crowns)\n",
    "\n",
    "# set up the output array\n",
    "nchar = np.max([len(label) for label in unique_labels])\n",
    "crown_labels = np.chararray(len(training_id), itemsize=nchar)\n",
    "\n",
    "for i in range(n_crowns):\n",
    "    index_crown = training_id == unique_crowns[i]\n",
    "    index_label = crown_id == unique_crowns[i]\n",
    "    crown_labels[index_crown] = species_id[index_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5161, 351)\n"
     ]
    }
   ],
   "source": [
    "mask = outliers.with_pca(features.drop(columns=\"siteID\"), thresh=argv.threshold)\n",
    "features.siteID= features.siteID.cat.codes\n",
    "# subset all data using the mask for future analyses\n",
    "features = np.array(features.drop(columns=\"crown_id\"))[mask]\n",
    "training_id = np.array(training_id[mask])\n",
    "crown_labels = np.array(crown_labels[mask])\n",
    "print(np.delete(features, 0, 1).shape)\n",
    "reducer, fixed_features = transform.pca(np.delete(features, 0, 1), argv.n_features)\n",
    "features = np.column_stack((features[:,0], fixed_features))\n",
    "features, crown_labels, training_id = resample.uniform(features, crown_labels, other_array=training_id)\n",
    "stratify = crown_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll split the data into three parts - model training, model calibration, and model test data\n",
    "xtrain, xcalib, ytrain, ycalib, strain, scalib = model_selection.train_test_split(\n",
    "        features, crown_labels, stratify, test_size=0.5, stratify=stratify)\n",
    "\n",
    "xctrain, xctest, yctrain, yctest, sctrain, sctest = model_selection.train_test_split(\n",
    "    xcalib, ycalib, scalib, test_size=0.5, stratify=scalib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 =  MERF()\n",
    "#models = [m3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(np.delete(xtrain, 0, 1))\n",
    "Z_train = np.ones((len(X_train), 1)) #pd.DataFrame(np.ones(ytrain.shape[0]))\n",
    "clusters_train = pd.Series(xtrain[:,0]).astype('int64')\n",
    "y_train = pd.Series(ytrain).astype('int64')\n",
    "wtrain = ccbid.get_sample_weights(ytrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
